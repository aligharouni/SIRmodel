\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{xcolor}

\newcommand{\fady}[1]{\textcolor{cyan}{$\langle${\slshape{\bfseries Fady:} #1 }$\rangle$}}
\newcommand{\Rnum}{\mathcal{R}_0}
\setlength{\parindent}{0pt} 
\usepackage{amsmath}
\usepackage{xspace}
\usepackage[nameinlink,capitalize]{cleveref}
\crefname{appendix}{Appendix}{Appendices}
\Crefname{appendix}{Appendix}{Appendices}
\title{SIRtesting}
\setlength{\parskip}{1em}
\begin{document}

\maketitle

\section{Introduction}

Much of this document concerns the effect of $\omega$ (the rate at which test results are returned) on $\Rnum$. As shown by Ali, when the overall testing rate $t$ is small (i.e., $t \approx 0$), the sign of $\partial{\Rnum}/\partial{\omega}$ is determined by a quadratic. 

For a relatively clean description of these roots, see starting from \cref{eq:defQ}. We show that there is always two real roots; one negative and one positive. For $w \in (0, \infty)$, there is a global maximum at the second root. For a necessary and sufficient condition (inequality) for having $\partial{\Rnum}/\partial{\omega} < 0$, see \cref{eq:necsuf}.

\section{Effect of speed of returning test results, $\omega$}

From Ali's analysis we know:

the Taylor expansion of $\Rnum$ around $t=0$ is
\begin{equation}
\Rnum \approx \beta/\gamma + \frac{\beta t}{\omega (\omega+\gamma) \gamma^2 W_s} \Big(\gamma(\eta_w-1)(\gamma W_s+\omega W_i) + (\eta_t -1)P_iW_i \omega^2 \Big) + \mathcal{O}(t^2). 
\end{equation}

Based on the above Taylor expansion around $t=0$, $$\partial{\Rnum}/\partial{\omega}=  \frac{-\beta t}{\gamma W_s\omega^2 (\gamma+\omega)^2}  (a \omega^2 + b \omega + c), $$

where $a=(\eta_w-1)W_i-(\eta_t-1)P_iW_i$, $b=2(\eta_w-1)\gamma W_s$ and $c=(\eta_w-1)\gamma^2 W_s$. Given that $\eta_t\leq \eta_w$, it is inferred that $a\geq 0$, $b\leq 0$ and $c \leq 0$. Let $\omega_1<0$ and $\omega_2>0$ be the roots of the quadratic expression in $\partial{\Rnum}/\partial{\omega}$. Thus, $\partial{\Rnum}/\partial{\omega}>0$ for $0<\omega<\omega_2$ and $\partial{\Rnum}/\partial{\omega}<0$ for $\omega>\omega_2$.

\hrulefill

Defining the following quantity, $Q$, will help us write the roots of $\partial{\Rnum}/\partial{\omega}$ neatly. 
\begin{align}\label{eq:defQ}
    Q =& \frac{W_i}{W_s}\left(1-\frac{n_{t}-1}{n_{w}-1}P_{i}\right) \\
\end{align}

Since $n_w > n_t$ and $P_i \approx 1$, we know that $Q < 0$.

With that in mind, we can write the roots of $\partial{\Rnum}/\partial{\omega}$ as

\begin{align}
    \omega_1 =& \frac{\gamma}{-\sqrt{1-Q}-1} \\
    \omega_2 =& \frac{\gamma}{\sqrt{1-Q}-1}
\end{align}

It is easy to confirm that $\omega_1 < 0$ by looking at the denominator. To see that $\omega_2 > 0$, recall that $Q < 0$, so $\sqrt{1-Q} > 1$ and so $\sqrt{1-Q} -1 > 0$. Knowing that $\omega_1 < 0$, our only root of interest (i.e., biologically relevant) is $\omega_2$. 

With some analysis, we can prove that $\partial{\Rnum}/\partial{\omega} > 0$ when $\omega \in (0,\omega_2)$ and $\partial{\Rnum}/\partial{\omega} < 0$ when $\omega \in (\omega_2,\infty)$. So we know that $\Rnum$ has a global maximum with respect to $\omega$ at $\omega = \omega_2$.

Before we look for strategies to minimize $\Rnum$ wrt to $\omega$, let us first discuss the behaviour of $\omega_2$ first. This may give us biological insight into when it is beneficial (i.e., lowers $\Rnum$) to return test results faster, and when it is not. \textbf{It is extremely important to note that all of this analysis is done with the linearization of $\Rnum$ around $t = 0$ as shown above, thus, this analysis holds only for small $t$.}

Suppose that $\omega > \omega_2$. By the previous analysis, this is equivalent to saying that increases in $\omega$ cause decreases in $\Rnum$. For what parameter regions is this true? To understand this, we examine the inequality

\begin{align}\label{eq:necsuf}
    &\omega > \omega_2 \nonumber \\
    &\omega > \frac{\gamma}{\sqrt{1-Q}-1} \nonumber \\
    &\vdots \nonumber \\
    &\frac{1-n_{t}}{1-n_{w}}P_{i}>\frac{W_{s}}{W_{i}}\left(\frac{\gamma}{\omega}+1\right)^{2}
\end{align}

The previous inequality is a necessary and sufficient condition for $\Rnum$ to be \emph{decreasing} with respect to $\omega$. In other words, it tells us exactly under what circumstances tests should be returned more rapidly and when they should not be. We can give a biological interpretation as follows:

The left hand side is a measure of the relative lowering in contact for the groups whose tests results are confirmed to be positive, compared to those whose test results are pending. As the difference between these two becomes extreme (i.e., as $\eta_t \ll \eta_{w}$), the LHS becomes larger, which means that returning test results faster may become beneficial. The whole left term is scaled by $P_i$, which is the sensitivity of the test. All of this makes sense with our biological intuition; it is useful to return test results quickly when the test is sensitive, and the benefit to positive individuals finding out they are positive outweighs the risk of negative individuals increasing their contact rate upon finding out they do not have the virus.

\fady{The RHS doesn't have as clean an interpretation, I think. But I'll add in more stuff here later.}

\section{Few high sensitivity tests vs. many low sensitivity tests}

Let us consider the linearization of $\Rnum$ around $\Rnum \approx 0$. \fady{As Ali pointed out to me, working with the linearization is okay since $\rho$ is the \text{daily per capita testing rate}, so it is expected to be fairly small. I was somehow thinking values of $\rho$ weren't gonna be small, but now I understand.}

\begin{equation}
\Rnum \approx \beta/\gamma + \frac{\beta t}{\omega (\omega+\gamma) \gamma^2 W_s} \Big(\gamma(\eta_w-1)(\gamma W_s+\omega W_i) + (\eta_t -1)P_iW_i \omega^2 \Big). 
\end{equation}

One can conceptualize two extremes of testing strategies: use only expensive high-sensitivity tests, but have a low testing rate as a result vs. use cheap low-sensitivity tests (thus, risking many false negatives), but have a high testing rate as a result. 

As a first step, consider a test that allows us to test at rate $\rho_1$ and has sensitivity $P_{i,1}$, and another test that allows us to test at $\rho_2$ and has sensitivity $P_{i,2}$. Under the assumption that $\rho_1 > \rho_2$, \cref{eq:rho1vsrho2} tells us exactly when the second test causes a lower $\Rnum$ compared to the first. 
\begin{align}\label{eq:rho1vsrho2}
    &\rho_1\left(\gamma(\eta_w-1)(\gamma W_s + \omega W_i) + (\eta_t-1)P_{i, 1}W_i\omega^2\right) - \rho_2\left(\gamma(\eta_w-1)(\gamma W_s + \omega W_i) + (\eta_t-1)P_{i, 2}W_i\omega^2\right) > 0 \nonumber \\
    &\vdots \nonumber \\
    &\frac{\rho_2P_{i, 2}-\rho_1P_{i, 1} }{\rho_1-\rho_2} > \frac{1-\eta_w}{1-\eta_t}\cdot \frac{\gamma(\gamma W_s + \omega W_i)}{\omega^2 W_i}
\end{align}

The previous inequality tells us precisely when a test corresponding to $\rho_2, P_{i,2}$ will yield a lower $\Rnum$ than a test corresponding to $\rho_1, P_{i,1}$, where $\rho_1 > \rho_2$. It is then natural to ask, what hypothetical test corresponding to $\rho^*, P_{i,*}$ will \textit{minimize} $\Rnum$? In order to examine this question, we can consider $P_i$ (which is the sensitivity of the test) as a function of the testing rate, $\rho$. So let $P_i(\rho)$. We expect that $P_i(\rho)$ is decreasing. 

We can then compute $\frac{\partial \Rnum}{\partial \rho}$ using the chain rule. Doing so, we obtain:
\begin{equation}
\frac{\partial \Rnum}{\partial \rho} = \dfrac{\beta\left(\left(\eta_\text{t}-1\right)\omega^2W_iP_i't+\left(\eta_t-1\right)\omega^2W_iP_i+\left(\eta_w-1\right)W_s\gamma^2+\left(\eta_w-1\right)\omega W_i\gamma\right)}{\omega W_s\gamma^2\left(\gamma+\omega\right)}\,,
\end{equation}

Setting $\frac{\partial \Rnum}{\partial \rho} = 0$:

\begin{align}\label{eq:r0rho=0}
    &\frac{\partial \Rnum(\rho^*)}{\partial \rho} = 0 \nonumber \\
    &\Longleftrightarrow P_i'(\rho^*) = \frac{1}{\rho^*} \left( \frac{1-\eta_w}{1-\eta_t}\cdot\frac{\gamma}{\omega}\cdot\big(\frac{\gamma}{\omega}+\frac{W_i}{W_s}\big) - P_i(\rho^*)\right)
\end{align}

In order to check if this critical point is a minimum, we can check the sign of the second derivative. For convenience, let $Q = \frac{1-\eta_w}{1-\eta_t}\cdot\frac{\gamma}{\omega}\cdot\big(\frac{\gamma}{\omega}+\frac{W_i}{W_s}\big)$

\begin{align}
    P_i''(\rho^*) &= \frac{-1}{{\rho^*}^2}(Q-P_i(\rho^*)) -\frac{1}{{\rho^*}^2}P_i'(\rho^*) \\
    &= -\frac{1}{{\rho^*}}P_i'(\rho^*) -\frac{1}{{\rho^*}^2}P_i'(\rho^*) > 0
\end{align}
Where the final inequality follows since $\rho^* > 0$ and $P_i'(\rho^*) < 0$. So indeed, the critical point we found is a minimum. 

To gain some intuition, let us assume that $P_i(\rho)$ is of the form $1-k\rho$ for some $k > 0$. \fady{to be continued...}

\end{document}


